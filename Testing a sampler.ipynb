{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magdalena Augusty≈Ñska"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5b (Testing a sampler).** In this problem we will attempt to check whether the sampler we created in **Problem 2c** works correctly. To this end we will use a chi-squared goodness-of-fit test. This test works as follows:\n",
    " * Let $p_1,\\ldots,p_d$ be the date frequencies as in the text file, scaled down to sum up to 1.\n",
    " * Use the sampler to generate a sample of dates. Let $c_1,\\ldots,c_d$ be the observed counts, and let $f_i=Np_i$ be the expected counts, where $N$ is the sample size. \n",
    " * Compute the test statistic $$S = \\sum_{i=1}^d \\frac{\\left(c_i-f_i\\right)^2}{f_i}.$$\n",
    " * Our base assumption (the null hypothesis) $H_0$ is that our sampler works correctly. If $H_0$ is true AND if the expected count for each bucket is large enough, then $S$ has (approximately) a $\\chi^2$ distribution with $d-1$ degrees of freedom. \n",
    " * Look up how likely is getting an $S$ value as large as the one you obtained if it has that distribution, i.e. the $p$-value. To do this use **scipy.stats.chi2.cdf**. If this value turns out smaller than the assumed threshold, e.g. $0.05$, we reject $H_0$. Otherwise we do not (we support $H_0$), but this does not mean $H_0$ is proved!\n",
    " * We mentioned earlier that expected counts for the buckets need to be large enough. \"Large enough\" assumption here is used to guarantee that $c_i$ are distributed approximately normally. Typically one requires that all counts are at least $5$. This is not the case in our problem (unless we take a huge sample) because of the errors in the data. The typical approach is to glue several buckets into one but this does not help in our case. Instead, ignore the erroneous dates when computing $c_i$ and $f_i$ and run the test again (on the same sample!). Remember to use a different number of degrees of freedom. Compare the results. \n",
    " * Perform the same test using **scipy.stats.chisquare** and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let $p_1,\\ldots,p_d$ be the date frequencies as in the text file, scaled down to sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../rpis/lab1/us_births_69_88.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_births = sum(data['births'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = [data['births'][i]/all_births for i in range(data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = len(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the sampler to generate a sample of dates. Let $c_1,\\ldots,c_d$ be the observed counts, and let $f_i=Np_i$ be the expected counts, where $N$ is the sample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(probabilities):\n",
    "    V = np.mean(probabilities)\n",
    "    days = len(probabilities)\n",
    "    buckets = np.empty(days, dtype=list)\n",
    "    for i in range(days):\n",
    "        bucket = [[i+1], [probabilities[i]]]\n",
    "        buckets[i] = bucket \n",
    "                          \n",
    "    while True:\n",
    "        A_index = next((index for index, value in enumerate(buckets) if len(value[0]) == 1 and value[1][0] < V), None)\n",
    "        B_index = next((index for index, value in enumerate(buckets) if len(value[0]) == 1 and value[1][0] > V), None)\n",
    "        if A_index is None or B_index is None:\n",
    "            break\n",
    "        to_transfer = V - buckets[A_index][1][0]\n",
    "        buckets[A_index][1].append(to_transfer)\n",
    "        buckets[A_index][0].append(buckets[B_index][0][0])\n",
    "        buckets[B_index][1][0] -= to_transfer\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_buckets_vec(buckets, size):\n",
    "    days_numbers = np.random.randint(len(buckets), size=size)\n",
    "    result = np.empty(size)\n",
    "    sampled_days = buckets[days_numbers]\n",
    "    prob = [sampled_days[i][1]/sum(sampled_days[i][1]) for i in range(size)]\n",
    "    for i in range(len(prob)):\n",
    "        if prob[i].shape[0] == 1:\n",
    "            prob[i] = np.pad(prob[i], pad_width=(0, 1), mode='constant')\n",
    "    prob = np.array(prob)\n",
    "    days = np.array([sampled_days[i][0] for i in range(size)])\n",
    "    c = prob.cumsum(axis=1)\n",
    "    u = np.random.rand(len(c), 1)\n",
    "    choices = (u < c).argmax(axis=1)\n",
    "    result = [days[i][choice] for i, choice in enumerate(choices)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date_buckets_vec(buckets):\n",
    "    step = 0\n",
    "    occ = [0] * len(buckets)\n",
    "    random_days = sample_from_buckets_vec(buckets, 10)\n",
    "    while True:\n",
    "        if step%10 == 0:\n",
    "            random_days = sample_from_buckets_vec(buckets, 10)\n",
    "        day = random_days[step%10]\n",
    "        step += 1\n",
    "        if (occ[day - 1]) == 1:\n",
    "            return step\n",
    "        else:\n",
    "            occ[day-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = simulate(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_buckets = [random_date_buckets_vec(buckets) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(result_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_expected(frequencies, sample_size):\n",
    "    return [sample_size*p for p in frequencies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_observed(size, counter):\n",
    "    observed = []\n",
    "    for i in range(size):\n",
    "        observed.append(counter[i + 1])\n",
    "    return observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = calculate_expected(freq, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = calculate_observed(d, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the test statistic $$S = \\sum_{i=1}^d \\frac{\\left(c_i-f_i\\right)^2}{f_i}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_stat(observed, expected):\n",
    "    S = 0\n",
    "    for i in range(len(expected)):\n",
    "        c_i = observed[i]\n",
    "        f_i = expected[i]\n",
    "        S += (c_i - f_i)**2/f_i\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98754.73918695652"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistic = compute_test_stat(counts, expected)\n",
    "statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our base assumption (the null hypothesis) $H_0$ is that our sampler works correctly. If $H_0$ is true AND if the expected count for each bucket is large enough, then $S$ has (approximately) a $\\chi^2$ distribution with $d-1$ degrees of freedom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look up how likely is getting an $S$ value as large as the one you obtained if it has that distribution, i.e. the $p$-value. To do this use **scipy.stats.chi2.cdf**. If this value turns out smaller than the assumed threshold, e.g. $0.05$, we reject $H_0$. Otherwise we do not (we support $H_0$), but this does not mean $H_0$ is proved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = 1.0 - chi2.cdf(statistic, d - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p$-value turns out smaller than the assumed threshold, e.g. $0.05$, therefore we reject $H_0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We mentioned earlier that expected counts for the buckets need to be large enough. \"Large enough\" assumption here is used to guarantee that $c_i$ are distributed approximately normally. Typically one requires that all counts are at least $5$. This is not the case in our problem (unless we take a huge sample) because of the errors in the data. The typical approach is to glue several buckets into one but this does not help in our case. Instead, ignore the erroneous dates when computing $c_i$ and $f_i$ and run the test again (on the same sample!). Remember to use a different number of degrees of freedom. Compare the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove rows representing days that don't exist int he calendar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../rpis/lab1/us_births_69_88.csv')\n",
    "for i in [2, 4, 6, 9, 11]:\n",
    "    data.drop(data.index[(data['month'] == i) & (data['day'] == 31)], inplace = True)\n",
    "    \n",
    "data.drop(data.index[(data['month'] == 2) & (data['day'] == 30)], inplace = True)\n",
    "data.index = range(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_births = sum(data['births'])\n",
    "freq = [data['births'][i]/all_births for i in range(data.shape[0])]\n",
    "d = len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = simulate(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_buckets = [random_date_buckets_vec(buckets) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(result_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = calculate_expected(freq, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = calculate_observed(d, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79062.48783165358"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistic = compute_test_stat(observed, expected)\n",
    "statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = 1.0 - chi2.cdf(statistic, d - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p$-value ia again smaller than the assumed threshold, e.g. $0.05$, therefore we reject $H_0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the same test using **scipy.stats.chisquare** and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = chisquare(observed, expected)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p$-value ia again equal 0 and we reject $H_0$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
